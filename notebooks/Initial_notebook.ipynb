{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path related configuration\n",
    "DATASET_BASE_DIR = Path(\"/home/italolanza/workspace/TG/dataset\")\n",
    "\n",
    "NORMAL_FILES = glob.glob(str(DATASET_BASE_DIR) + '/normal/*.csv')\n",
    "\n",
    "HOR_MISALIGNMENT_LOW_FILES = glob.glob(str(DATASET_BASE_DIR) + '/horizontal/0.5mm/*.csv')\n",
    "\n",
    "HOR_MISALIGNMENT_MEDIUM_FILES = glob.glob(str(DATASET_BASE_DIR) + '/horizontal/1.0mm/*.csv') \\\n",
    "                                + glob.glob(str(DATASET_BASE_DIR) + '/horizontal/1.5mm/*.csv')\n",
    "\n",
    "HOR_MISALIGNMENT_HIGH_FILES = glob.glob(str(DATASET_BASE_DIR) + '/horizontal/2.0mm/*.csv')\n",
    "\n",
    "VER_MISALIGNMENT_LOW_FILES = glob.glob(str(DATASET_BASE_DIR) + '/vertical/0.51mm/*.csv') \\\n",
    "                                + glob.glob(str(DATASET_BASE_DIR) + '/vertical/0.63mm/*.csv')\n",
    "\n",
    "VER_MISALIGNMENT_MEDIUM_FILES = glob.glob(str(DATASET_BASE_DIR) + '/vertical/1.27mm/*.csv') \\\n",
    "                                + glob.glob(str(DATASET_BASE_DIR) + '/vertical/1.40mm/*.csv')\n",
    "\n",
    "VER_MISALIGNMENT_HIGH_FILES = glob.glob(str(DATASET_BASE_DIR) + '/vertical/1.78mm/*.csv') \\\n",
    "                                + glob.glob(str(DATASET_BASE_DIR) + '/vertical/1.90mm/*.csv')\n",
    "\n",
    "IMBALANCE_LOW_FILES = glob.glob(str(DATASET_BASE_DIR) + '/imbalance/6g/*.csv') \\\n",
    "                        + glob.glob(str(DATASET_BASE_DIR) + '/imbalance/10g/*.csv')\n",
    "\n",
    "IMBALANCE_MEDIUM_FILES = glob.glob(str(DATASET_BASE_DIR) + '/imbalance/15g/*.csv') \\\n",
    "                        + glob.glob(str(DATASET_BASE_DIR) + '/imbalance/20g/*.csv') \\\n",
    "                        + glob.glob(str(DATASET_BASE_DIR) + '/imbalance/25g/*.csv')\n",
    "\n",
    "IMBALANCE_HIGH_FILES = glob.glob(str(DATASET_BASE_DIR) + '/imbalance/30g/*.csv') \\\n",
    "                        + glob.glob(str(DATASET_BASE_DIR) + '/imbalance/35g/*.csv')\n",
    "\n",
    "OUTPUT_DATA_DIR = DATASET_BASE_DIR.joinpath(\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal data\n",
    "def process_normal_data():\n",
    "    \n",
    "    if (Path.exists(OUTPUT_DATA_DIR.joinpath(\"normal_data.csv\"))):\n",
    "        return\n",
    " \n",
    "    \n",
    "    OUTPUT_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for file_name in NORMAL_FILES:\n",
    "\n",
    "        data_list = list()\n",
    "\n",
    "        with open(file_name, 'r') as data_file:\n",
    "            data_iter = csv.reader(data_file, delimiter=\",\")            \n",
    "            for data in data_iter:\n",
    "                # data.extend([0, 0.0])\n",
    "                data_list.append(data)\n",
    "\n",
    "        \n",
    "        with open(OUTPUT_DATA_DIR.joinpath(\"normal_data.csv\"), 'a') as output_file:\n",
    "            writer = csv.writer(output_file)\n",
    "            writer.writerows(data_list)\n",
    "    \n",
    "    # return pd.read_csv(OUTPUT_DATA_DIR.joinpath(\"normal_data.csv\"), chunksize=chunk_size, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imbalance data\n",
    "def process_imbalance_data():\n",
    "    \n",
    "    # IMBALANCE_OUTPUT_FILES=[\"imbalance_low_data.csv\", \"imbalance_medium_data.csv\", \"imbalance_high_data.csv\"]\n",
    "\n",
    "\n",
    "    # if (Path.exists( OUTPUT_DATA_DIR.joinpath(\"imbalance_data.csv\")) ):\n",
    "    #     df = pd.read_csv( OUTPUT_DATA_DIR.joinpath(\"imbalance_data.csv\"),chunksize=chunk_size )\n",
    "    #     return df\n",
    " \n",
    "\n",
    "    OUTPUT_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Low criticality (6g, 10g)\n",
    "    if not ( Path.exists(OUTPUT_DATA_DIR.joinpath(\"imbalance_low_data.csv\")) ):\n",
    "        for file_name in IMBALANCE_LOW_FILES:\n",
    "\n",
    "            data_list = list()\n",
    "\n",
    "            with open(file_name, 'r') as data_file:\n",
    "                data_iter = csv.reader(data_file, delimiter=\",\")\n",
    "                for data in data_iter:\n",
    "                    # data.extend([1, 1.0])\n",
    "                    data_list.append(data)\n",
    "            \n",
    "            with open(OUTPUT_DATA_DIR.joinpath(\"imbalance_low_data.csv\"), 'a') as output_file:\n",
    "                writer = csv.writer(output_file)\n",
    "                writer.writerows(data_list)\n",
    "    \n",
    "    # Medium criticality (15g, 20g, 25g)\n",
    "    if not ( Path.exists(OUTPUT_DATA_DIR.joinpath(\"imbalance_medium_data.csv\")) ):\n",
    "        for file_name in IMBALANCE_MEDIUM_FILES:\n",
    "\n",
    "            data_list = list()\n",
    "\n",
    "            with open(file_name, 'r') as data_file:\n",
    "                data_iter = csv.reader(data_file, delimiter=\",\")                \n",
    "                for data in data_iter:\n",
    "                    # data.extend([1, 2.0])\n",
    "                    data_list.append(data)\n",
    "            \n",
    "            with open(OUTPUT_DATA_DIR.joinpath(\"imbalance_medium_data.csv\"), 'a') as output_file:\n",
    "                writer = csv.writer(output_file)\n",
    "                writer.writerows(data_list)\n",
    "    \n",
    "    # High criticality (30g, 35g)\n",
    "    if not ( Path.exists(OUTPUT_DATA_DIR.joinpath(\"imbalance_high_data.csv\")) ):\n",
    "        for file_name in IMBALANCE_HIGH_FILES:\n",
    "\n",
    "            data_list = list()\n",
    "\n",
    "            with open(file_name, 'r') as data_file:\n",
    "                data_iter = csv.reader(data_file, delimiter=\",\")                \n",
    "                for data in data_iter:\n",
    "                    # data.extend([1, 3.0])\n",
    "                    data_list.append(data)    \n",
    "\n",
    "            \n",
    "            with open(OUTPUT_DATA_DIR.joinpath(\"imbalance_high_data.csv\"), 'a') as output_file:\n",
    "                writer = csv.writer(output_file)\n",
    "                writer.writerows(data_list)\n",
    "\n",
    "\n",
    "    # # Join imbalance files in one file\n",
    "    # for file_name in IMBALANCE_OUTPUT_FILES:\n",
    "\n",
    "    #         data_list = list()\n",
    "\n",
    "    #         with open(OUTPUT_DATA_DIR.joinpath(file_name), 'r') as data_file:\n",
    "    #             data_iter = csv.reader(data_file, delimiter=\",\")\n",
    "    #             data_list.extend( [data for data in data_iter] )\n",
    "            \n",
    "    #         with open(OUTPUT_DATA_DIR.joinpath(\"imbalance_data.csv\"), 'a') as output_file:\n",
    "    #             writer = csv.writer(output_file)\n",
    "    #             writer.writerows(data_list)\n",
    "\n",
    "\n",
    "    # return {\n",
    "    #     \"low\": pd.read_csv(OUTPUT_DATA_DIR.joinpath(\"normal_data.csv\"), chunksize=chunk_size, header=None),\n",
    "    #     \"medium\": pd.read_csv(OUTPUT_DATA_DIR.joinpath(\"normal_data.csv\"), chunksize=chunk_size, header=None),\n",
    "    #     \"high\": pd.read_csv(OUTPUT_DATA_DIR.joinpath(\"normal_data.csv\"), chunksize=chunk_size, header=None)\n",
    "    # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontal misalignment\n",
    "def process_hor_misalignment_data():\n",
    "    \n",
    "    # HOR_MISLAGNMENT_OUTPUT_FILES=[\"hor_misalignment_low_data.csv\", \"hor_misalignment_medium_data.csv\", \"hor_misalignment_high_data.csv\"]\n",
    "\n",
    "\n",
    "    # if (Path.exists( OUTPUT_DATA_DIR.joinpath(\"hor_misalignment_data.csv\")) ):\n",
    "    #     df = pd.read_csv( OUTPUT_DATA_DIR.joinpath(\"hor_misalignment_data.csv\"),chunksize=chunk_size )\n",
    "    #     return df\n",
    "\n",
    " \n",
    "\n",
    "    OUTPUT_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Low criticality (6g, 10g)\n",
    "    if not ( Path.exists(OUTPUT_DATA_DIR.joinpath(\"hor_misalignment_low_data.csv\")) ):\n",
    "        for file_name in IMBALANCE_LOW_FILES:\n",
    "\n",
    "            data_list = list()\n",
    "\n",
    "            with open(file_name, 'r') as data_file:\n",
    "                data_iter = csv.reader(data_file, delimiter=\",\")\n",
    "                for data in data_iter:\n",
    "                    # data.extend([2, 1.0])\n",
    "                    data_list.append(data)\n",
    "            \n",
    "            with open(OUTPUT_DATA_DIR.joinpath(\"hor_misalignment_low_data.csv\"), 'a') as output_file:\n",
    "                writer = csv.writer(output_file)\n",
    "                writer.writerows(data_list)\n",
    "    \n",
    "    # Medium criticality (15g, 20g, 25g)\n",
    "    if not ( Path.exists(OUTPUT_DATA_DIR.joinpath(\"hor_misalignment_medium_data.csv\")) ):\n",
    "        for file_name in IMBALANCE_MEDIUM_FILES:\n",
    "\n",
    "            data_list = list()\n",
    "\n",
    "            with open(file_name, 'r') as data_file:\n",
    "                data_iter = csv.reader(data_file, delimiter=\",\")                \n",
    "                for data in data_iter:\n",
    "                    # data.extend([2, 2.0])\n",
    "                    data_list.append(data)\n",
    "            \n",
    "            with open(OUTPUT_DATA_DIR.joinpath(\"hor_misalignment_medium_data.csv\"), 'a') as output_file:\n",
    "                writer = csv.writer(output_file)\n",
    "                writer.writerows(data_list)\n",
    "    \n",
    "    # High criticality (30g, 35g)\n",
    "    if not ( Path.exists(OUTPUT_DATA_DIR.joinpath(\"hor_misalignment_high_data.csv\")) ):\n",
    "        for file_name in IMBALANCE_HIGH_FILES:\n",
    "\n",
    "            data_list = list()\n",
    "\n",
    "            with open(file_name, 'r') as data_file:\n",
    "                data_iter = csv.reader(data_file, delimiter=\",\")                \n",
    "                for data in data_iter:\n",
    "                    # data.extend([2, 3.0])\n",
    "                    data_list.append(data)    \n",
    "\n",
    "            \n",
    "            with open(OUTPUT_DATA_DIR.joinpath(\"hor_misalignment_high_data.csv\"), 'a') as output_file:\n",
    "                writer = csv.writer(output_file)\n",
    "                writer.writerows(data_list)\n",
    "\n",
    "\n",
    "#    # Join hor_misalignment files in one file\n",
    "#     for file_name in HOR_MISLAGNMENT_OUTPUT_FILES:\n",
    "\n",
    "#             data_list = list()\n",
    "\n",
    "#             with open(OUTPUT_DATA_DIR.joinpath(file_name), 'r') as data_file:\n",
    "#                 data_iter = csv.reader(data_file, delimiter=\",\")\n",
    "#                 data_list.extend( [data for data in data_iter] )\n",
    "            \n",
    "#             with open(OUTPUT_DATA_DIR.joinpath(\"hor_misalignment_data.csv\"), 'a') as output_file:\n",
    "#                 writer = csv.writer(output_file)\n",
    "#                 writer.writerows(data_list)\n",
    "\n",
    "\n",
    "#     return pd.read_csv(OUTPUT_DATA_DIR.joinpath(\"hor_misalignment_data.csv\"), chunksize=chunk_size, header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertical misalignment\n",
    "def process_ver_misalignment_data():\n",
    "    \n",
    "    # VER_MISLAGNMENT_OUTPUT_FILES=[\"ver_misalignment_low_data.csv\", \"ver_misalignment_medium_data.csv\", \"ver_misalignment_high_data.csv\"]\n",
    "\n",
    "\n",
    "    # if (Path.exists( OUTPUT_DATA_DIR.joinpath(\"ver_misalignment_data.csv\")) ):\n",
    "    #     df = pd.read_csv( OUTPUT_DATA_DIR.joinpath(\"ver_misalignment_data.csv\"),chunksize=chunk_size )\n",
    "    #     return df\n",
    "\n",
    " \n",
    "\n",
    "    OUTPUT_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Low criticality (6g, 10g)\n",
    "    if not ( Path.exists(OUTPUT_DATA_DIR.joinpath(\"ver_misalignment_low_data.csv\")) ):\n",
    "        for file_name in IMBALANCE_LOW_FILES:\n",
    "\n",
    "            data_list = list()\n",
    "\n",
    "            with open(file_name, 'r') as data_file:\n",
    "                data_iter = csv.reader(data_file, delimiter=\",\")\n",
    "                for data in data_iter:\n",
    "                    # data.extend([3, 1.0])\n",
    "                    data_list.append(data)\n",
    "            \n",
    "            with open(OUTPUT_DATA_DIR.joinpath(\"ver_misalignment_low_data.csv\"), 'a') as output_file:\n",
    "                writer = csv.writer(output_file)\n",
    "                writer.writerows(data_list)\n",
    "    \n",
    "    # Medium criticality (15g, 20g, 25g)\n",
    "    if not ( Path.exists(OUTPUT_DATA_DIR.joinpath(\"ver_misalignment_medium_data.csv\")) ):\n",
    "        for file_name in IMBALANCE_MEDIUM_FILES:\n",
    "\n",
    "            data_list = list()\n",
    "\n",
    "            with open(file_name, 'r') as data_file:\n",
    "                data_iter = csv.reader(data_file, delimiter=\",\")                \n",
    "                for data in data_iter:\n",
    "                    # data.extend([3, 2.0])\n",
    "                    data_list.append(data)\n",
    "            \n",
    "            with open(OUTPUT_DATA_DIR.joinpath(\"ver_misalignment_medium_data.csv\"), 'a') as output_file:\n",
    "                writer = csv.writer(output_file)\n",
    "                writer.writerows(data_list)\n",
    "    \n",
    "    # High criticality (30g, 35g)\n",
    "    if not ( Path.exists(OUTPUT_DATA_DIR.joinpath(\"ver_misalignment_high_data.csv\")) ):\n",
    "        for file_name in IMBALANCE_HIGH_FILES:\n",
    "\n",
    "            data_list = list()\n",
    "\n",
    "            with open(file_name, 'r') as data_file:\n",
    "                data_iter = csv.reader(data_file, delimiter=\",\")                \n",
    "                for data in data_iter:\n",
    "                    # data.extend([3, 3.0])\n",
    "                    data_list.append(data)    \n",
    "\n",
    "            \n",
    "            with open(OUTPUT_DATA_DIR.joinpath(\"ver_misalignment_high_data.csv\"), 'a') as output_file:\n",
    "                writer = csv.writer(output_file)\n",
    "                writer.writerows(data_list)\n",
    "\n",
    "\n",
    "#    # Join hor_misalignment files in one file\n",
    "#     for file_name in HOR_MISLAGNMENT_OUTPUT_FILES:\n",
    "\n",
    "#             data_list = list()\n",
    "\n",
    "#             with open(OUTPUT_DATA_DIR.joinpath(file_name), 'r') as data_file:\n",
    "#                 data_iter = csv.reader(data_file, delimiter=\",\")\n",
    "#                 data_list.extend( [data for data in data_iter] )\n",
    "            \n",
    "#             with open(OUTPUT_DATA_DIR.joinpath(\"hor_misalignment_data.csv\"), 'a') as output_file:\n",
    "#                 writer = csv.writer(output_file)\n",
    "#                 writer.writerows(data_list)\n",
    "\n",
    "\n",
    "#     return pd.read_csv(OUTPUT_DATA_DIR.joinpath(\"hor_misalignment_data.csv\"), chunksize=chunk_size, header=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process normal data\n",
    "process_normal_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process imbalance data\n",
    "process_imbalance_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process horizontal misalignment data\n",
    "process_hor_misalignment_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process vertical  misalignment data\n",
    "process_ver_misalignment_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Func to get the normal data\n",
    "def get_normal_data(chunk_size):\n",
    "    if (Path.exists(OUTPUT_DATA_DIR.joinpath(\"normal_data.csv\"))):\n",
    "        df = pd.read_csv(OUTPUT_DATA_DIR.joinpath(\"normal_data.csv\"),chunksize=chunk_size )\n",
    "        return df\n",
    "\n",
    "\n",
    "# Func to get the imbalance data\n",
    "def get_imbalance_data(chunk_size):\n",
    "\n",
    "    IMBALANCE_OUTPUT_FILES = [\"imbalance_low_data.csv\", \"imbalance_medium_data.csv\", \"imbalance_high_data.csv\"]\n",
    "    ImbalanceData = namedtuple(\"ImbalanceData\", \"low_imb_data med_imb_data high_imb_data\")\n",
    "    \n",
    "    data = list()\n",
    "\n",
    "\n",
    "    if Path.exists(OUTPUT_DATA_DIR.joinpath(\"imbalance_low_data.csv\")) \\\n",
    "        and Path.exists(OUTPUT_DATA_DIR.joinpath(\"imbalance_medium_data.csv\")) \\\n",
    "        and Path.exists(OUTPUT_DATA_DIR.joinpath(\"imbalance_high_data.csv\")):\n",
    "\n",
    "        for data_type in IMBALANCE_OUTPUT_FILES:\n",
    "            data.append(pd.read_csv(OUTPUT_DATA_DIR.joinpath(data_type),chunksize=chunk_size ))\n",
    "\n",
    "    return ImbalanceData(data[0],data[1],data[2])\n",
    "\n",
    "\n",
    "# Func to get the horizontal misalignment data\n",
    "def get_horizontal_misalignment_data(chunk_size):\n",
    "\n",
    "    HOR_MISALIGNMENT_OUTPUT_FILES = [\"hor_misalignment_low_data.csv\", \"hor_misalignment_medium_data.csv\", \"hor_misalignment_high_data.csv\"]\n",
    "    HorMisalignmentData = namedtuple(\"HorMisalignmentData\", [\"low_hor_mis_data\", \"med_hor_mis_data\", \"high_hor_mis_data\"])\n",
    "    \n",
    "    data = list()\n",
    "\n",
    "\n",
    "    if Path.exists(OUTPUT_DATA_DIR.joinpath(\"hor_misalignment_low_data.csv\")) \\\n",
    "        and Path.exists(OUTPUT_DATA_DIR.joinpath(\"hor_misalignment_medium_data.csv\")) \\\n",
    "        and Path.exists(OUTPUT_DATA_DIR.joinpath(\"hor_misalignment_high_data.csv\")):\n",
    "\n",
    "        for data_type in HOR_MISALIGNMENT_OUTPUT_FILES:\n",
    "            data.append(pd.read_csv(OUTPUT_DATA_DIR.joinpath(data_type),chunksize=chunk_size ))\n",
    "\n",
    "    return HorMisalignmentData(data[0],data[1],data[2])\n",
    "\n",
    "\n",
    "# Func to get the vertical misalignment data\n",
    "def get_vertical_misalignment_data(chunk_size):\n",
    "\n",
    "    VER_MISALIGNMENT_OUTPUT_FILES = [\"ver_misalignment_low_data.csv\", \"ver_misalignment_medium_data.csv\", \"ver_misalignment_high_data.csv\"]\n",
    "    VerMisalignmentData = namedtuple(\"VerMisalignmentData\", [\"low_ver_mis_data\", \"med_ver_mis_data\", \"high_ver_mis_data\"])\n",
    "    \n",
    "    data = list()\n",
    "\n",
    "\n",
    "    if Path.exists(OUTPUT_DATA_DIR.joinpath(\"ver_misalignment_low_data.csv\")) \\\n",
    "        and Path.exists(OUTPUT_DATA_DIR.joinpath(\"ver_misalignment_medium_data.csv\")) \\\n",
    "        and Path.exists(OUTPUT_DATA_DIR.joinpath(\"ver_misalignment_high_data.csv\")):\n",
    "\n",
    "        for data_type in VER_MISALIGNMENT_OUTPUT_FILES:\n",
    "            data.append(pd.read_csv(OUTPUT_DATA_DIR.joinpath(data_type),chunksize=chunk_size ))\n",
    "\n",
    "    return VerMisalignmentData(data[0],data[1],data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imbalance_data)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
